{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk  #importing natural language tool kit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords #importing the stopwords from nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/rakshitmalhotra/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt') #downloading the needed punkt package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rakshitmalhotra/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords') #downloading the needed stopwords package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob #importing glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math #importing math and all its avaliable inbuilt functionalities with *\n",
    "from math import *\n",
    "line=''\n",
    "wordlist=list()\n",
    "s=set()\n",
    "path='Folders/Assessment1/*.txt'\n",
    "flist=glob.glob(path) #reading the list of needed files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Folders/Assessment1/asses-1-text3.txt', 'Folders/Assessment1/asses-1-text2.txt', 'Folders/Assessment1/asses-1-text1.txt', 'Folders/Assessment1/asses-1-text4.txt']\n"
     ]
    }
   ],
   "source": [
    "print(flist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['hello', 'my', 'name', 'is', 'ray', 'saksham', 'khan', '.', 'i', 'am', 'from', 'jalandhar', '.', 'i', 'study', 'in', 'vit', '.', 'my', 'favourite', 'programming', 'language', 'is', 'java', '.', 'i', 'use', 'java', 'for', 'data', 'science', 'as', 'well', 'as', 'for', 'web', 'development', '.', 'i', 'am', 'a', 'board', 'member', 'at', 'csi-vit', '.'], ['hello', 'my', 'name', 'is', 'adit', 'kumar', '.', 'i', 'am', 'from', 'jammu', 'and', 'kashmir', '.', 'i', 'study', 'in', 'vit', '.', 'my', 'favourite', 'programming', 'language', 'is', 'c++', '.', 'my', 'family', 'belongs', 'to', 'khyber', 'district', 'of', 'pakistan', '.', 'i', 'love', 'to', 'eat', 'and', 'sleep', 'a', 'lot', 'and', 'hence', 'my', 'pet', 'name', 'is', 'panda'], ['hello', 'my', 'name', 'is', 'rakshit', '.', 'i', 'am', 'from', 'delhi', '.', 'i', 'study', 'in', 'vit', '.', 'my', 'favourite', 'programming', 'language', 'is', 'python', '.', 'i', 'use', 'python', 'for', 'data', 'science', 'as', 'well', 'as', 'for', 'web', 'development', '', '.'], ['hello', 'my', 'name', 'is', 'virat', 'kohli', '.', 'i', 'am', 'the', 'captain', 'of', 'indian', 'cricket', 'team', '.', 'i', 'work', 'hard', 'and', 'belong', 'to', 'delhi', '.', 'i', 'have', 'been', 'rated', 'as', 'the', 'best', 'batsman', 'in', 'the', 'world', 'by', 'many', 'former', 'cricketers', 'and', 'i', 'love', 'to', 'win', 'matches']]\n",
      "\n",
      "\n",
      "\n",
      "['', '.', 'a', 'adit', 'am', 'and', 'as', 'at', 'batsman', 'been', 'belong', 'belongs', 'best', 'board', 'by', 'c++', 'captain', 'cricket', 'cricketers', 'csi-vit', 'data', 'delhi', 'development', 'district', 'eat', 'family', 'favourite', 'for', 'former', 'from', 'hard', 'have', 'hello', 'hence', 'i', 'in', 'indian', 'is', 'jalandhar', 'jammu', 'java', 'kashmir', 'khan', 'khyber', 'kohli', 'kumar', 'language', 'lot', 'love', 'many', 'matches', 'member', 'my', 'name', 'of', 'pakistan', 'panda', 'pet', 'programming', 'python', 'rakshit', 'rated', 'ray', 'saksham', 'science', 'sleep', 'study', 'team', 'the', 'to', 'use', 'virat', 'vit', 'web', 'well', 'win', 'work', 'world']\n"
     ]
    }
   ],
   "source": [
    "for fname in flist:  \n",
    "    tfile=open(fname,\"r\") \n",
    "    line=tfile.read().strip() \n",
    "    line=line.lower() \n",
    "    tfile.close()\n",
    "    s=s.union(set(line.split(' '))) \n",
    "    wordlist.append(list(line.split(' '))) \n",
    "print(wordlist)\n",
    "print(\"\\n\\n\")\n",
    "s=sorted(s) \n",
    "print(s) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "st=set(stopwords.words('english')) #set of stopwords of enlgish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STOPWORDS REMOVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adit', 'batsman', 'belong', 'belongs', 'best', 'board', 'c++', 'captain', 'cricket', 'cricketers', 'csi-vit', 'data', 'delhi', 'development', 'district', 'eat', 'family', 'favourite', 'former', 'hard', 'hello', 'hence', 'indian', 'jalandhar', 'jammu', 'java', 'kashmir', 'khan', 'khyber', 'kohli', 'kumar', 'language', 'lot', 'love', 'many', 'matches', 'member', 'name', 'pakistan', 'panda', 'pet', 'programming', 'python', 'rakshit', 'rated', 'ray', 'saksham', 'science', 'sleep', 'study', 'team', 'use', 'virat', 'vit', 'web', 'well', 'win', 'work', 'world']\n"
     ]
    }
   ],
   "source": [
    "import string #importing string\n",
    "l=list() #making a new list\n",
    "for x in s: \n",
    "    if x.lower() not in st and x not in string.punctuation:\n",
    "        l.append(x)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,1,0,0,\n",
      "0,0,0,1,\n",
      "0,1,0,1,\n",
      "0,1,0,0,\n",
      "0,0,0,1,\n",
      "1,0,0,0,\n",
      "0,1,0,0,\n",
      "0,0,0,1,\n",
      "0,0,0,2,\n",
      "0,0,0,1,\n",
      "1,0,0,0,\n",
      "1,0,1,0,\n",
      "0,0,1,1,\n",
      "1,0,1,0,\n",
      "0,1,0,0,\n",
      "0,1,0,0,\n",
      "0,1,0,0,\n",
      "1,1,1,0,\n",
      "0,0,0,1,\n",
      "0,0,0,1,\n",
      "1,1,1,1,\n",
      "0,1,0,0,\n",
      "0,0,0,1,\n",
      "1,0,0,0,\n",
      "0,1,0,0,\n",
      "2,0,0,0,\n",
      "0,1,0,0,\n",
      "1,0,0,0,\n",
      "0,1,0,0,\n",
      "0,0,0,1,\n",
      "0,1,0,0,\n",
      "1,1,1,0,\n",
      "0,1,0,0,\n",
      "0,1,0,1,\n",
      "0,0,0,1,\n",
      "0,0,0,1,\n",
      "1,0,0,0,\n",
      "1,2,1,1,\n",
      "0,1,0,0,\n",
      "0,1,0,0,\n",
      "0,1,0,0,\n",
      "1,1,1,0,\n",
      "0,0,2,0,\n",
      "0,0,1,0,\n",
      "0,0,0,1,\n",
      "1,0,0,0,\n",
      "1,0,0,0,\n",
      "1,0,1,0,\n",
      "0,1,0,0,\n",
      "1,1,1,0,\n",
      "0,0,0,1,\n",
      "1,0,1,0,\n",
      "0,0,0,1,\n",
      "2,1,1,0,\n",
      "1,0,1,0,\n",
      "1,0,1,0,\n",
      "0,0,0,1,\n",
      "0,0,0,1,\n",
      "0,0,0,1,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "ct=0\n",
    "tf_line=''\n",
    "doc_counts=[]\n",
    "for term in l:\n",
    "    doc_counts.append(0)\n",
    "    for fdoc in flist:\n",
    "        doc=open(fdoc)\n",
    "        line=doc.read().lower()\n",
    "        doc.close()\n",
    "        #print(line)\n",
    "        ct=line.count(str(term))\n",
    "        tf_line+=str(ct)+','\n",
    "        if(ct>0):\n",
    "            doc_counts[i]+=1\n",
    "    i+=1\n",
    "    tf_line= tf_line.strip()+'\\n'\n",
    "print(tf_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEMMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adit\n",
      "batsm\n",
      "belong\n",
      "best\n",
      "board\n",
      "c++\n",
      "captain\n",
      "cricket\n",
      "csi-vit\n",
      "dat\n",
      "delh\n",
      "develop\n",
      "district\n",
      "eat\n",
      "famy\n",
      "favourit\n",
      "form\n",
      "hard\n",
      "hello\n",
      "hent\n",
      "ind\n",
      "jalandh\n",
      "jammu\n",
      "jav\n",
      "kashmir\n",
      "khan\n",
      "khyb\n",
      "kohl\n",
      "kum\n",
      "langu\n",
      "lot\n",
      "lov\n",
      "many\n",
      "match\n",
      "memb\n",
      "nam\n",
      "pak\n",
      "pand\n",
      "pet\n",
      "program\n",
      "python\n",
      "rakshit\n",
      "rat\n",
      "ray\n",
      "saksham\n",
      "sci\n",
      "sleep\n",
      "study\n",
      "team\n",
      "us\n",
      "vir\n",
      "vit\n",
      "web\n",
      "wel\n",
      "win\n",
      "work\n",
      "world\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "ls=LancasterStemmer()\n",
    "stem=list()\n",
    "for word in l:\n",
    "    if ls.stem(word) not in stem:\n",
    "        stem.append(word)\n",
    "        print(ls.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 0]\n",
      "[0, 0, 0, 1]\n",
      "[0, 1, 0, 1]\n",
      "[0, 0, 0, 1]\n",
      "[1, 0, 0, 0]\n",
      "[0, 1, 0, 0]\n",
      "[0, 0, 0, 1]\n",
      "[0, 0, 0, 2]\n",
      "[1, 0, 0, 0]\n",
      "[1, 0, 1, 0]\n",
      "[0, 0, 1, 1]\n",
      "[1, 0, 1, 0]\n",
      "[0, 1, 0, 0]\n",
      "[0, 1, 0, 0]\n",
      "[0, 1, 0, 0]\n",
      "[1, 1, 1, 0]\n",
      "[0, 0, 0, 1]\n",
      "[0, 0, 0, 1]\n",
      "[1, 1, 1, 1]\n",
      "[0, 1, 0, 0]\n",
      "[0, 0, 0, 1]\n",
      "[1, 0, 0, 0]\n",
      "[0, 1, 0, 0]\n",
      "[2, 0, 0, 0]\n",
      "[0, 1, 0, 0]\n",
      "[1, 0, 0, 0]\n",
      "[0, 1, 0, 0]\n",
      "[0, 0, 0, 1]\n",
      "[0, 1, 0, 0]\n",
      "[1, 1, 1, 0]\n",
      "[0, 1, 0, 0]\n",
      "[0, 1, 0, 1]\n",
      "[0, 0, 0, 1]\n",
      "[0, 0, 0, 1]\n",
      "[1, 0, 0, 0]\n",
      "[1, 2, 1, 1]\n",
      "[0, 1, 0, 0]\n",
      "[0, 1, 0, 0]\n",
      "[0, 1, 0, 0]\n",
      "[1, 1, 1, 0]\n",
      "[0, 0, 2, 0]\n",
      "[0, 0, 1, 0]\n",
      "[0, 0, 0, 1]\n",
      "[1, 0, 0, 0]\n",
      "[1, 0, 0, 0]\n",
      "[1, 0, 1, 0]\n",
      "[0, 1, 0, 0]\n",
      "[1, 1, 1, 0]\n",
      "[0, 0, 0, 1]\n",
      "[1, 0, 1, 0]\n",
      "[0, 0, 0, 1]\n",
      "[2, 1, 1, 0]\n",
      "[1, 0, 1, 0]\n",
      "[1, 0, 1, 0]\n",
      "[0, 0, 0, 1]\n",
      "[0, 0, 0, 1]\n",
      "[0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "j=0\n",
    "count=0\n",
    "tf_line_1=list()\n",
    "doc_counts_1=[]\n",
    "\n",
    "for term in stem:\n",
    "    doc_counts_1.append(0)\n",
    "    temp=list()\n",
    "    for fdoc in flist:\n",
    "        doc=open(fdoc)\n",
    "        line=doc.read().lower()\n",
    "        doc.close()\n",
    "        #print(line)\n",
    "        count=line.count(str(term))\n",
    "        temp.append(count)\n",
    "        if(count>0):\n",
    "            doc_counts_1[j]+=1\n",
    "    tf_line_1.append(temp)            \n",
    "    print(tf_line_1[j])\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 3, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 2, 1, 1, 1, 4, 1, 1, 1, 3, 1, 1, 1, 1, 1, 2, 1, 3, 1, 2, 1, 3, 2, 2, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(doc_counts_1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf=list()\n",
    "for i in doc_counts_1:\n",
    "    idf_cal=math.log((1+len(flist))/i)\n",
    "    idf.append(idf_cal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.6094379124341003,\n",
       " 1.6094379124341003,\n",
       " 0.9162907318741551,\n",
       " 1.6094379124341003,\n",
       " 1.6094379124341003,\n",
       " 1.6094379124341003,\n",
       " 1.6094379124341003,\n",
       " 1.6094379124341003,\n",
       " 1.6094379124341003,\n",
       " 0.9162907318741551,\n",
       " 0.9162907318741551,\n",
       " 0.9162907318741551,\n",
       " 1.6094379124341003,\n",
       " 1.6094379124341003,\n",
       " 1.6094379124341003,\n",
       " 0.5108256237659907,\n",
       " 1.6094379124341003,\n",
       " 1.6094379124341003,\n",
       " 0.22314355131420976,\n",
       " 1.6094379124341003,\n",
       " 1.6094379124341003,\n",
       " 1.6094379124341003,\n",
       " 1.6094379124341003,\n",
       " 1.6094379124341003,\n",
       " 1.6094379124341003,\n",
       " 1.6094379124341003,\n",
       " 1.6094379124341003,\n",
       " 1.6094379124341003,\n",
       " 1.6094379124341003,\n",
       " 0.5108256237659907,\n",
       " 1.6094379124341003,\n",
       " 0.9162907318741551,\n",
       " 1.6094379124341003,\n",
       " 1.6094379124341003,\n",
       " 1.6094379124341003,\n",
       " 0.22314355131420976,\n",
       " 1.6094379124341003,\n",
       " 1.6094379124341003,\n",
       " 1.6094379124341003,\n",
       " 0.5108256237659907,\n",
       " 1.6094379124341003,\n",
       " 1.6094379124341003,\n",
       " 1.6094379124341003,\n",
       " 1.6094379124341003,\n",
       " 1.6094379124341003,\n",
       " 0.9162907318741551,\n",
       " 1.6094379124341003,\n",
       " 0.5108256237659907,\n",
       " 1.6094379124341003,\n",
       " 0.9162907318741551,\n",
       " 1.6094379124341003,\n",
       " 0.5108256237659907,\n",
       " 0.9162907318741551,\n",
       " 0.9162907318741551,\n",
       " 1.6094379124341003,\n",
       " 1.6094379124341003,\n",
       " 1.6094379124341003]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 0, 0],\n",
       " [0, 0, 0, 1],\n",
       " [0, 1, 0, 1],\n",
       " [0, 0, 0, 1],\n",
       " [1, 0, 0, 0],\n",
       " [0, 1, 0, 0],\n",
       " [0, 0, 0, 1],\n",
       " [0, 0, 0, 2],\n",
       " [1, 0, 0, 0],\n",
       " [1, 0, 1, 0],\n",
       " [0, 0, 1, 1],\n",
       " [1, 0, 1, 0],\n",
       " [0, 1, 0, 0],\n",
       " [0, 1, 0, 0],\n",
       " [0, 1, 0, 0],\n",
       " [1, 1, 1, 0],\n",
       " [0, 0, 0, 1],\n",
       " [0, 0, 0, 1],\n",
       " [1, 1, 1, 1],\n",
       " [0, 1, 0, 0],\n",
       " [0, 0, 0, 1],\n",
       " [1, 0, 0, 0],\n",
       " [0, 1, 0, 0],\n",
       " [2, 0, 0, 0],\n",
       " [0, 1, 0, 0],\n",
       " [1, 0, 0, 0],\n",
       " [0, 1, 0, 0],\n",
       " [0, 0, 0, 1],\n",
       " [0, 1, 0, 0],\n",
       " [1, 1, 1, 0],\n",
       " [0, 1, 0, 0],\n",
       " [0, 1, 0, 1],\n",
       " [0, 0, 0, 1],\n",
       " [0, 0, 0, 1],\n",
       " [1, 0, 0, 0],\n",
       " [1, 2, 1, 1],\n",
       " [0, 1, 0, 0],\n",
       " [0, 1, 0, 0],\n",
       " [0, 1, 0, 0],\n",
       " [1, 1, 1, 0],\n",
       " [0, 0, 2, 0],\n",
       " [0, 0, 1, 0],\n",
       " [0, 0, 0, 1],\n",
       " [1, 0, 0, 0],\n",
       " [1, 0, 0, 0],\n",
       " [1, 0, 1, 0],\n",
       " [0, 1, 0, 0],\n",
       " [1, 1, 1, 0],\n",
       " [0, 0, 0, 1],\n",
       " [1, 0, 1, 0],\n",
       " [0, 0, 0, 1],\n",
       " [2, 1, 1, 0],\n",
       " [1, 0, 1, 0],\n",
       " [1, 0, 1, 0],\n",
       " [0, 0, 0, 1],\n",
       " [0, 0, 0, 1],\n",
       " [0, 0, 0, 1]]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tf_line_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "div=list()\n",
    "for i in range(0,len(wordlist)):\n",
    "    div.append(len(wordlist[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[46, 50, 37, 45]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.02, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.022222222222222223]\n",
      "[0.0, 0.02, 0.0, 0.022222222222222223]\n",
      "[0.0, 0.0, 0.0, 0.022222222222222223]\n",
      "[0.021739130434782608, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.02, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.022222222222222223]\n",
      "[0.0, 0.0, 0.0, 0.044444444444444446]\n",
      "[0.021739130434782608, 0.0, 0.0, 0.0]\n",
      "[0.021739130434782608, 0.0, 0.02702702702702703, 0.0]\n",
      "[0.0, 0.0, 0.02702702702702703, 0.022222222222222223]\n",
      "[0.021739130434782608, 0.0, 0.02702702702702703, 0.0]\n",
      "[0.0, 0.02, 0.0, 0.0]\n",
      "[0.0, 0.02, 0.0, 0.0]\n",
      "[0.0, 0.02, 0.0, 0.0]\n",
      "[0.021739130434782608, 0.02, 0.02702702702702703, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.022222222222222223]\n",
      "[0.0, 0.0, 0.0, 0.022222222222222223]\n",
      "[0.021739130434782608, 0.02, 0.02702702702702703, 0.022222222222222223]\n",
      "[0.0, 0.02, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.022222222222222223]\n",
      "[0.021739130434782608, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.02, 0.0, 0.0]\n",
      "[0.043478260869565216, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.02, 0.0, 0.0]\n",
      "[0.021739130434782608, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.02, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.022222222222222223]\n",
      "[0.0, 0.02, 0.0, 0.0]\n",
      "[0.021739130434782608, 0.02, 0.02702702702702703, 0.0]\n",
      "[0.0, 0.02, 0.0, 0.0]\n",
      "[0.0, 0.02, 0.0, 0.022222222222222223]\n",
      "[0.0, 0.0, 0.0, 0.022222222222222223]\n",
      "[0.0, 0.0, 0.0, 0.022222222222222223]\n",
      "[0.021739130434782608, 0.0, 0.0, 0.0]\n",
      "[0.021739130434782608, 0.04, 0.02702702702702703, 0.022222222222222223]\n",
      "[0.0, 0.02, 0.0, 0.0]\n",
      "[0.0, 0.02, 0.0, 0.0]\n",
      "[0.0, 0.02, 0.0, 0.0]\n",
      "[0.021739130434782608, 0.02, 0.02702702702702703, 0.0]\n",
      "[0.0, 0.0, 0.05405405405405406, 0.0]\n",
      "[0.0, 0.0, 0.02702702702702703, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.022222222222222223]\n",
      "[0.021739130434782608, 0.0, 0.0, 0.0]\n",
      "[0.021739130434782608, 0.0, 0.0, 0.0]\n",
      "[0.021739130434782608, 0.0, 0.02702702702702703, 0.0]\n",
      "[0.0, 0.02, 0.0, 0.0]\n",
      "[0.021739130434782608, 0.02, 0.02702702702702703, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.022222222222222223]\n",
      "[0.021739130434782608, 0.0, 0.02702702702702703, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.022222222222222223]\n",
      "[0.043478260869565216, 0.02, 0.02702702702702703, 0.0]\n",
      "[0.021739130434782608, 0.0, 0.02702702702702703, 0.0]\n",
      "[0.021739130434782608, 0.0, 0.02702702702702703, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.022222222222222223]\n",
      "[0.0, 0.0, 0.0, 0.022222222222222223]\n",
      "[0.0, 0.0, 0.0, 0.022222222222222223]\n"
     ]
    }
   ],
   "source": [
    "divid=list()\n",
    "for i in tf_line_1:\n",
    "    new=list()\n",
    "    for j in range(0,len(flist)):\n",
    "        calci=i[j]/div[j]\n",
    "        new.append(calci)\n",
    "    divid.append(new)\n",
    "    print(new)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CALCULATING TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "tfidf=list()\n",
    "for i in range(0,len(divid)):\n",
    "    tfidf.append(np.asarray(divid[i])*idf[i]) #USING NUMPY AS LIST CAN'T BE MULTIPLIED WITH FLOAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.03218876 0.         0.        ]\n",
      "[0.         0.         0.         0.03576529]\n",
      "[0.         0.01832581 0.         0.02036202]\n",
      "[0.         0.         0.         0.03576529]\n",
      "[0.03498778 0.         0.         0.        ]\n",
      "[0.         0.03218876 0.         0.        ]\n",
      "[0.         0.         0.         0.03576529]\n",
      "[0.         0.         0.         0.07153057]\n",
      "[0.03498778 0.         0.         0.        ]\n",
      "[0.01991936 0.         0.02476461 0.        ]\n",
      "[0.         0.         0.02476461 0.02036202]\n",
      "[0.01991936 0.         0.02476461 0.        ]\n",
      "[0.         0.03218876 0.         0.        ]\n",
      "[0.         0.03218876 0.         0.        ]\n",
      "[0.         0.03218876 0.         0.        ]\n",
      "[0.0111049  0.01021651 0.0138061  0.        ]\n",
      "[0.         0.         0.         0.03576529]\n",
      "[0.         0.         0.         0.03576529]\n",
      "[0.00485095 0.00446287 0.00603091 0.00495875]\n",
      "[0.         0.03218876 0.         0.        ]\n",
      "[0.         0.         0.         0.03576529]\n",
      "[0.03498778 0.         0.         0.        ]\n",
      "[0.         0.03218876 0.         0.        ]\n",
      "[0.06997556 0.         0.         0.        ]\n",
      "[0.         0.03218876 0.         0.        ]\n",
      "[0.03498778 0.         0.         0.        ]\n",
      "[0.         0.03218876 0.         0.        ]\n",
      "[0.         0.         0.         0.03576529]\n",
      "[0.         0.03218876 0.         0.        ]\n",
      "[0.0111049  0.01021651 0.0138061  0.        ]\n",
      "[0.         0.03218876 0.         0.        ]\n",
      "[0.         0.01832581 0.         0.02036202]\n",
      "[0.         0.         0.         0.03576529]\n",
      "[0.         0.         0.         0.03576529]\n",
      "[0.03498778 0.         0.         0.        ]\n",
      "[0.00485095 0.00892574 0.00603091 0.00495875]\n",
      "[0.         0.03218876 0.         0.        ]\n",
      "[0.         0.03218876 0.         0.        ]\n",
      "[0.         0.03218876 0.         0.        ]\n",
      "[0.0111049  0.01021651 0.0138061  0.        ]\n",
      "[0.         0.         0.08699664 0.        ]\n",
      "[0.         0.         0.04349832 0.        ]\n",
      "[0.         0.         0.         0.03576529]\n",
      "[0.03498778 0.         0.         0.        ]\n",
      "[0.03498778 0.         0.         0.        ]\n",
      "[0.01991936 0.         0.02476461 0.        ]\n",
      "[0.         0.03218876 0.         0.        ]\n",
      "[0.0111049  0.01021651 0.0138061  0.        ]\n",
      "[0.         0.         0.         0.03576529]\n",
      "[0.01991936 0.         0.02476461 0.        ]\n",
      "[0.         0.         0.         0.03576529]\n",
      "[0.02220981 0.01021651 0.0138061  0.        ]\n",
      "[0.01991936 0.         0.02476461 0.        ]\n",
      "[0.01991936 0.         0.02476461 0.        ]\n",
      "[0.         0.         0.         0.03576529]\n",
      "[0.         0.         0.         0.03576529]\n",
      "[0.         0.         0.         0.03576529]\n"
     ]
    }
   ],
   "source": [
    "len(new)\n",
    "for i in tfidf:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 0.02, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.022222222222222223],\n",
       " [0.0, 0.02, 0.0, 0.022222222222222223],\n",
       " [0.0, 0.0, 0.0, 0.022222222222222223],\n",
       " [0.021739130434782608, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.02, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.022222222222222223],\n",
       " [0.0, 0.0, 0.0, 0.044444444444444446],\n",
       " [0.021739130434782608, 0.0, 0.0, 0.0],\n",
       " [0.021739130434782608, 0.0, 0.02702702702702703, 0.0],\n",
       " [0.0, 0.0, 0.02702702702702703, 0.022222222222222223],\n",
       " [0.021739130434782608, 0.0, 0.02702702702702703, 0.0],\n",
       " [0.0, 0.02, 0.0, 0.0],\n",
       " [0.0, 0.02, 0.0, 0.0],\n",
       " [0.0, 0.02, 0.0, 0.0],\n",
       " [0.021739130434782608, 0.02, 0.02702702702702703, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.022222222222222223],\n",
       " [0.0, 0.0, 0.0, 0.022222222222222223],\n",
       " [0.021739130434782608, 0.02, 0.02702702702702703, 0.022222222222222223],\n",
       " [0.0, 0.02, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.022222222222222223],\n",
       " [0.021739130434782608, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.02, 0.0, 0.0],\n",
       " [0.043478260869565216, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.02, 0.0, 0.0],\n",
       " [0.021739130434782608, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.02, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.022222222222222223],\n",
       " [0.0, 0.02, 0.0, 0.0],\n",
       " [0.021739130434782608, 0.02, 0.02702702702702703, 0.0],\n",
       " [0.0, 0.02, 0.0, 0.0],\n",
       " [0.0, 0.02, 0.0, 0.022222222222222223],\n",
       " [0.0, 0.0, 0.0, 0.022222222222222223],\n",
       " [0.0, 0.0, 0.0, 0.022222222222222223],\n",
       " [0.021739130434782608, 0.0, 0.0, 0.0],\n",
       " [0.021739130434782608, 0.04, 0.02702702702702703, 0.022222222222222223],\n",
       " [0.0, 0.02, 0.0, 0.0],\n",
       " [0.0, 0.02, 0.0, 0.0],\n",
       " [0.0, 0.02, 0.0, 0.0],\n",
       " [0.021739130434782608, 0.02, 0.02702702702702703, 0.0],\n",
       " [0.0, 0.0, 0.05405405405405406, 0.0],\n",
       " [0.0, 0.0, 0.02702702702702703, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.022222222222222223],\n",
       " [0.021739130434782608, 0.0, 0.0, 0.0],\n",
       " [0.021739130434782608, 0.0, 0.0, 0.0],\n",
       " [0.021739130434782608, 0.0, 0.02702702702702703, 0.0],\n",
       " [0.0, 0.02, 0.0, 0.0],\n",
       " [0.021739130434782608, 0.02, 0.02702702702702703, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.022222222222222223],\n",
       " [0.021739130434782608, 0.0, 0.02702702702702703, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.022222222222222223],\n",
       " [0.043478260869565216, 0.02, 0.02702702702702703, 0.0],\n",
       " [0.021739130434782608, 0.0, 0.02702702702702703, 0.0],\n",
       " [0.021739130434782608, 0.0, 0.02702702702702703, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.022222222222222223],\n",
       " [0.0, 0.0, 0.0, 0.022222222222222223],\n",
       " [0.0, 0.0, 0.0, 0.022222222222222223]]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "divid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.        , 0.03218876, 0.        , 0.        ]),\n",
       " array([0.        , 0.        , 0.        , 0.03576529]),\n",
       " array([0.        , 0.01832581, 0.        , 0.02036202]),\n",
       " array([0.        , 0.        , 0.        , 0.03576529]),\n",
       " array([0.03498778, 0.        , 0.        , 0.        ]),\n",
       " array([0.        , 0.03218876, 0.        , 0.        ]),\n",
       " array([0.        , 0.        , 0.        , 0.03576529]),\n",
       " array([0.        , 0.        , 0.        , 0.07153057]),\n",
       " array([0.03498778, 0.        , 0.        , 0.        ]),\n",
       " array([0.01991936, 0.        , 0.02476461, 0.        ]),\n",
       " array([0.        , 0.        , 0.02476461, 0.02036202]),\n",
       " array([0.01991936, 0.        , 0.02476461, 0.        ]),\n",
       " array([0.        , 0.03218876, 0.        , 0.        ]),\n",
       " array([0.        , 0.03218876, 0.        , 0.        ]),\n",
       " array([0.        , 0.03218876, 0.        , 0.        ]),\n",
       " array([0.0111049 , 0.01021651, 0.0138061 , 0.        ]),\n",
       " array([0.        , 0.        , 0.        , 0.03576529]),\n",
       " array([0.        , 0.        , 0.        , 0.03576529]),\n",
       " array([0.00485095, 0.00446287, 0.00603091, 0.00495875]),\n",
       " array([0.        , 0.03218876, 0.        , 0.        ]),\n",
       " array([0.        , 0.        , 0.        , 0.03576529]),\n",
       " array([0.03498778, 0.        , 0.        , 0.        ]),\n",
       " array([0.        , 0.03218876, 0.        , 0.        ]),\n",
       " array([0.06997556, 0.        , 0.        , 0.        ]),\n",
       " array([0.        , 0.03218876, 0.        , 0.        ]),\n",
       " array([0.03498778, 0.        , 0.        , 0.        ]),\n",
       " array([0.        , 0.03218876, 0.        , 0.        ]),\n",
       " array([0.        , 0.        , 0.        , 0.03576529]),\n",
       " array([0.        , 0.03218876, 0.        , 0.        ]),\n",
       " array([0.0111049 , 0.01021651, 0.0138061 , 0.        ]),\n",
       " array([0.        , 0.03218876, 0.        , 0.        ]),\n",
       " array([0.        , 0.01832581, 0.        , 0.02036202]),\n",
       " array([0.        , 0.        , 0.        , 0.03576529]),\n",
       " array([0.        , 0.        , 0.        , 0.03576529]),\n",
       " array([0.03498778, 0.        , 0.        , 0.        ]),\n",
       " array([0.00485095, 0.00892574, 0.00603091, 0.00495875]),\n",
       " array([0.        , 0.03218876, 0.        , 0.        ]),\n",
       " array([0.        , 0.03218876, 0.        , 0.        ]),\n",
       " array([0.        , 0.03218876, 0.        , 0.        ]),\n",
       " array([0.0111049 , 0.01021651, 0.0138061 , 0.        ]),\n",
       " array([0.        , 0.        , 0.08699664, 0.        ]),\n",
       " array([0.        , 0.        , 0.04349832, 0.        ]),\n",
       " array([0.        , 0.        , 0.        , 0.03576529]),\n",
       " array([0.03498778, 0.        , 0.        , 0.        ]),\n",
       " array([0.03498778, 0.        , 0.        , 0.        ]),\n",
       " array([0.01991936, 0.        , 0.02476461, 0.        ]),\n",
       " array([0.        , 0.03218876, 0.        , 0.        ]),\n",
       " array([0.0111049 , 0.01021651, 0.0138061 , 0.        ]),\n",
       " array([0.        , 0.        , 0.        , 0.03576529]),\n",
       " array([0.01991936, 0.        , 0.02476461, 0.        ]),\n",
       " array([0.        , 0.        , 0.        , 0.03576529]),\n",
       " array([0.02220981, 0.01021651, 0.0138061 , 0.        ]),\n",
       " array([0.01991936, 0.        , 0.02476461, 0.        ]),\n",
       " array([0.01991936, 0.        , 0.02476461, 0.        ]),\n",
       " array([0.        , 0.        , 0.        , 0.03576529]),\n",
       " array([0.        , 0.        , 0.        , 0.03576529]),\n",
       " array([0.        , 0.        , 0.        , 0.03576529])]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUERYING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " hello adit\n"
     ]
    }
   ],
   "source": [
    "query=input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokens=word_tokenize(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokens=sorted(word_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 0]\n",
      "[1, 1, 1, 1]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "j=0\n",
    "count=0\n",
    "tf_line_2=list()\n",
    "doc_counts_2=[]\n",
    "\n",
    "for term in word_tokens:\n",
    "    doc_counts_2.append(0)\n",
    "    temp=list()\n",
    "    for fdoc in flist:\n",
    "        doc=open(fdoc)\n",
    "        line=doc.read().lower()\n",
    "        doc.close()\n",
    "        #print(line)\n",
    "        count=line.count(str(term))\n",
    "        temp.append(count)\n",
    "        if(count>0):\n",
    "            doc_counts_2[j]+=1\n",
    "    tf_line_2.append(temp)            \n",
    "    print(tf_line_2[j])\n",
    "    j+=1\n",
    "print(len(tf_line_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "THE IDF FOR adit IS 1.6094379124341003\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "original tfidf is [0.         0.03218876 0.         0.        ]\n",
      "\n",
      "\n",
      "\n",
      "[0.05180581]\n",
      "\n",
      "\n",
      "\n",
      "[array([0.        , 1.60943791, 0.        , 0.        ])]\n",
      "\n",
      "\n",
      "\n",
      "[0.         0.03218876 0.         0.        ]\n",
      "\n",
      "\n",
      "\n",
      "0.05180580787960469\n",
      "0.05180580787960469\n",
      "\n",
      "\n",
      "\n",
      "THE RANKING IS FROM 1 TO 4, WHERE 1 IS REPRESENTS HIGHEST SIMILARITY\n",
      "---------------------------------------------\n",
      "[[2 1 3 4]]\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "THE IDF FOR hello IS 0.22314355131420976\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "original tfidf is [0.00485095 0.00446287 0.00603091 0.00495875]\n",
      "\n",
      "\n",
      "\n",
      "[0.00453059]\n",
      "\n",
      "\n",
      "\n",
      "[array([0.22314355, 0.22314355, 0.22314355, 0.22314355])]\n",
      "\n",
      "\n",
      "\n",
      "[0.00485095 0.00446287 0.00603091 0.00495875]\n",
      "\n",
      "\n",
      "\n",
      "0.004560213433366393\n",
      "0.004560213433366393\n",
      "\n",
      "\n",
      "\n",
      "THE RANKING IS FROM 1 TO 4, WHERE 1 IS REPRESENTS HIGHEST SIMILARITY\n",
      "---------------------------------------------\n",
      "[[3 4 1 2]]\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def square(list):\n",
    "    return [i ** 2 for i in list]\n",
    "cosine_sim=list()\n",
    "numiter=0\n",
    "for word in word_tokens:\n",
    "    for j in range(0,len(stem)):\n",
    "        tfidfq=list()\n",
    "        if(word == stem[j]):\n",
    "            print('\\n\\n')\n",
    "            print(\"THE IDF FOR \"+str(word)+\" IS \"+str(idf[j])+'\\n\\n')\n",
    "            #print(tf_line_2[k])\n",
    "            print('\\n\\n')\n",
    "            tfidfq.append(np.array(tf_line_2[numiter])*idf[j])\n",
    "            print(\"original tfidf is \" + str(tfidf[j]))\n",
    "            print('\\n\\n')\n",
    "            a=(np.sqrt(np.sum(square(tfidfq))))\n",
    "            b=(np.sqrt(np.sum(square(tfidf[j]))))\n",
    "            print((np.dot(tfidfq, tfidf[j])))\n",
    "            print('\\n\\n')\n",
    "            print(tfidfq)\n",
    "            print('\\n\\n')\n",
    "            print(tfidf[j])\n",
    "            print('\\n\\n')\n",
    "            something=a*b\n",
    "            print(something)\n",
    "            new_arr=(np.multiply(tfidfq,tfidf[j]))\n",
    "            bottom1=(np.sqrt(np.sum(np.square(tfidfq))))\n",
    "            bottom2=(np.sqrt(np.sum(np.square(tfidf[j]))))\n",
    "            multi=bottom1*bottom2\n",
    "            print(multi)\n",
    "            array=(np.divide(new_arr,multi))\n",
    "            order = (-array).argsort()\n",
    "            order=np.add(order,1)\n",
    "            print('\\n\\n')\n",
    "            print(\"THE RANKING IS FROM 1 TO 4, WHERE 1 IS REPRESENTS HIGHEST SIMILARITY\")\n",
    "            print('---------------------------------------------')\n",
    "            print(order) \n",
    "            print('---------------------------------------------')\n",
    "\n",
    "#             for i in range(0,int(tfidf[j])):\n",
    "#                 if i>0:\n",
    "#                     print(i)\n",
    "#                     print(\"********\")\n",
    "#                     cosine_sim.append(np.dot(tfidfq,i)/(np.sqrt(np.sum(square((tfidfq)))) * np.sqrt(np.sum(i**2))))\n",
    "#                     # print(k)\n",
    "#                     # print('------------')\n",
    "#                     # cosine_sim.append([a*b for a,b in zip(tfidfq,tfidf[j])] /(np.sqrt(np.sum(square((tfidfq)))) * np.sqrt(np.sum(tfidf[j]**2))))\n",
    "#                     #cosine_sim.append(np.dot(tfidfq, tfidf[j]) /something)\n",
    "#                     print(\"-------------------\")\n",
    "            numiter+=1\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
